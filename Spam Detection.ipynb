{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99d35fd2-9aca-4bea-b776-efcd963e5d06",
   "metadata": {},
   "source": [
    "Spam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f612ef2b-aa8c-487a-ba92-05ac32e75a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split , cross_val_score , cross_validate \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score , classification_report , make_scorer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e476aa-1100-430c-bbcf-9e87280937e9",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ffe7e9-7960-4678-895e-037df474e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"spam_ham_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "668a08b1-662b-4e9a-84b3-7e4a9083cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: x.replace('\\r\\n',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22b25cbb-c8cc-499f-ab97-feac03fd87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['label_num']\n",
    "X = data['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5885779-ca13-4b28-96b8-0e92b727eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "corpus = []\n",
    "\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "for i in range(len(X)) : \n",
    "    text = X.iloc[i].lower()\n",
    "    text = text.translate(str.maketrans('','',string.punctuation)).split()\n",
    "    text = [stemmer.stem(word) for word in text if word not in stopwords_set]\n",
    "    text = ' '.join(text)\n",
    "    corpus.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14411727-dcc8-4784-9bc3-2cd968277376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train  , X_test, y_train , y_test = train_test_split(corpus, y , test_size = 0.2 , random_state =42)\n",
    "#vectorizer = CountVectorizer()\n",
    "#X_train= vectorizer.fit_transform(X_train)\n",
    "#X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd02c4b6-1d5f-4677-8617-472db5f09059",
   "metadata": {},
   "source": [
    "KNN , SVM(Linear ,RBF ) , LOGISTIC REGRESSION , Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5861e5c8-e608-4aa7-85b7-b4b27d9b79fa",
   "metadata": {},
   "source": [
    "SVM LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed477631-d864-4cea-8367-2ce6d76cac6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.966\n",
      "Precision: 0.959\n",
      "Recall: 0.959\n",
      "F1-score: 0.959\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel= 'linear')\n",
    "\n",
    "pip_svm  = Pipeline([\n",
    "    ('vectorizer' , CountVectorizer()),\n",
    "    ('svm' , svm)\n",
    "])\n",
    "\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "\n",
    "results = cross_validate(pip_svm, corpus, y, cv=5, scoring=scoring)\n",
    "\n",
    " \n",
    "print(f\"Accuracy: {results['test_accuracy'].mean():.3f}\")\n",
    "print(f\"Precision: {results['test_precision'].mean():.3f}\")\n",
    "print(f\"Recall: {results['test_recall'].mean():.3f}\")\n",
    "print(f\"F1-score: {results['test_f1'].mean():.3f}\")\n",
    "\n",
    "#scores_svm_linear = cross_validate(pip_svm, corpus, y, cv=5)\n",
    "\n",
    "#print(f\" Accuracy: {scores_svm_linear.mean():.3f}\")\n",
    "\n",
    "#y_train_pred = svm.predict(X_train)\n",
    "#y_test_pred = svm.predict(X_test)\n",
    "\n",
    "#cross_score = cross_val_score(svm , corpus , y , cv = 5 ) \n",
    "#print(\"Scores for each fold:\", cross_score)\n",
    "#print(\"Mean accuracy:\", cross_score.mean())\n",
    "\n",
    "#print(f\"Acc SVM linear Kenrel : {svm.score(X_test,y_test)}\")\n",
    "#print(f\"Classfication report {classification_report(y_test , y_test_pred)}\")\n",
    "#print(f\"Training Score  : {svm.score(X_train, y_train)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ce5951-c694-4220-a2b1-3dabbd019e66",
   "metadata": {},
   "source": [
    "SVM RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8dba3ec-2306-4d26-bf72-6e0e8c4638d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.964\n",
      "Precision: 0.948\n",
      "Recall: 0.968\n",
      "F1-score: 0.957\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel= 'rbf')\n",
    "\n",
    "pip_svm_rbf = Pipeline([\n",
    "    ('vectorizer' , CountVectorizer()),\n",
    "    ('svm' , svm)])\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "\n",
    "results = cross_validate(pip_svm_rbf, corpus, y, cv=5, scoring=scoring)\n",
    "\n",
    " \n",
    "print(f\"Accuracy: {results['test_accuracy'].mean():.3f}\")\n",
    "print(f\"Precision: {results['test_precision'].mean():.3f}\")\n",
    "print(f\"Recall: {results['test_recall'].mean():.3f}\")\n",
    "print(f\"F1-score: {results['test_f1'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee1c61-ac63-400f-b265-de20e5247190",
   "metadata": {},
   "source": [
    "Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bc62e8c-41c9-4c8e-8a57-19f49876c408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.979\n",
      "Precision: 0.971\n",
      "Recall: 0.979\n",
      "F1-score: 0.975\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression(max_iter =1000)\n",
    "\n",
    "\n",
    "pipline_reg = Pipeline([\n",
    "    ('vectorizer' , CountVectorizer()),\n",
    "    ('log',log)])\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "\n",
    "results = cross_validate(pipline_reg, corpus, y, cv=5, scoring=scoring)\n",
    "\n",
    " \n",
    "print(f\"Accuracy: {results['test_accuracy'].mean():.3f}\")\n",
    "print(f\"Precision: {results['test_precision'].mean():.3f}\")\n",
    "print(f\"Recall: {results['test_recall'].mean():.3f}\")\n",
    "print(f\"F1-score: {results['test_f1'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17ae12-c636-4c68-8a77-aab4392f95d5",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da3a2f90-aba3-4adf-8403-e65cb40a7758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.825\n",
      "Precision: 0.804\n",
      "Recall: 0.863\n",
      "F1-score: 0.811\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "\n",
    "pipline_knn = Pipeline([\n",
    "    ('vectorizer',CountVectorizer()),\n",
    "    ('knn', knn)])\n",
    "\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "\n",
    "results = cross_validate(pipline_knn, corpus, y, cv=5, scoring=scoring)\n",
    "\n",
    " \n",
    "print(f\"Accuracy: {results['test_accuracy'].mean():.3f}\")\n",
    "print(f\"Precision: {results['test_precision'].mean():.3f}\")\n",
    "print(f\"Recall: {results['test_recall'].mean():.3f}\")\n",
    "print(f\"F1-score: {results['test_f1'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e837f723-81eb-4d93-8cf2-bfe2614c270d",
   "metadata": {},
   "source": [
    "Desicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "481b4246-3223-457f-8921-43799b09a4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.790\n",
      "Precision: 0.833\n",
      "Recall: 0.650\n",
      "F1-score: 0.667\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion=\"gini\", max_depth=3, random_state=42)\n",
    "\n",
    "pipline_clf = Pipeline([('vectorizer' , CountVectorizer()) , ('klf' , clf)])\n",
    "\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "\n",
    "results = cross_validate(pipline_clf, corpus, y, cv=5, scoring=scoring)\n",
    "\n",
    " \n",
    "print(f\"Accuracy: {results['test_accuracy'].mean():.3f}\")\n",
    "print(f\"Precision: {results['test_precision'].mean():.3f}\")\n",
    "print(f\"Recall: {results['test_recall'].mean():.3f}\")\n",
    "print(f\"F1-score: {results['test_f1'].mean():.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
